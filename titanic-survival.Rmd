---
title: |
  Modeling Titanic Survival
author:
  - name: Qiushi Yan
    affil: ""
    email: "qiushi.yann@gmail.com, website: https://qiushi.rbind.io"
affiliation:
  - num: a
    address: |
      Beijing, China
abstract: |
   This case study showcases the development of a binary logistic model to predict the possibility of survival in the loss of Titanic. I demonstrate the overall modeling process, including preprocessing, exploratory analysis,  model fitting, adjustment, bootstrap validation and interpretation as well as other relevant techniques such as redundancy analysis and multiple imputation for missing data. The motivation and justification behind critical statistical decisions are explained. This analysis is fully reproducible with all source R code and text. 
bibliography: references.bib
link-citations: true
geometry: "margin=1in"
colorlinks: yes
#appendix: appendix.tex
output:
  bookdown::pdf_book:
    base_format: rticles::tf_article
    includes:
      in_header: header.tex
    dev: "cairo_pdf"
    extra_dependencies:
      sourcecodepro:
       - scale=0.85
---

http://www.crema-research.ch/papers/2009-03.pdf

Who Survived Titanic? A Logistic Regression Analysis: https://sci-hub.do/https://journals.sagepub.com/doi/pdf/10.1177/084387140401600205


https://www.insider.com/titanic-secrets-facts-2018-4#at-the-memorial-of-frederick-fleet-one-of-the-lookouts-a-prankster-left-a-pair-of-binoculars-with-a-note-reading-sorry-for-bringing-these-100-years-too-late-8


http://rpubs.com/edwardcooper/titanic1

https://www.kaggle.com/mrisdal/exploring-survival-on-the-titanic/report

https://www.kaggle.com/startupsci/titanic-data-science-solutions/comments

https://www.newscientist.com/article/dn22119-sinking-the-titanic-women-and-children-first-myth/

```{r, include = FALSE}
# global chunk options 
knitr::opts_chunk$set(
  warning = FALSE,
  message = FALSE,
  comment = "",
  fig.align = "center",
  echo = FALSE
)

# load libraries 
library(dplyr) # data wrangling
library(ggplot2) # visualization
library(rms) # modeling
library(mice) # imputation for missing data
library(patchwork) # plot composition
library(rpart) # decision tree for mis
# latex print option
options(prType='latex')
# load raw data
t <- readr::read_csv("data/titanic.csv") 
# modify Hmisc::latex
mylatex <- function (...) {
    o <- capture.output(latex(...))
    # this will strip /all/ line-only comments
    o <- grep('^%', o, inv=T, value=T)
    cat(o, sep='\n')
}
# theme for ggplot2
ggplot2::theme_set(ymisc::theme_clean())
```




# Introduction 

The sinking of RMS Titanic brought to numerous machine learning competitions a quintessential dataset among others. After the "unsinkable" British passenger liner struck an iceberg in her maiden voyage on 15 April 1912 and was eventually wrecked, more than 1500 people perished. Decades of effort has been devoted to the study of the historic event, in which one major interest for statistical inquiries is to model and predict survival given a number of characteristics, since there was clear account that some people  were allowed to get on the lifeboat first.  

There are numerous variants of Titanic data existed on the web, with primary source based on [Encyclopedia Titanica](https://www.encyclopedia-titanica.org/) [-@hind],  a site started in 1996 as an attempt to tell the story of every person that traveled the Titanic as a passenger or
crew member. This project is based on the most recent version as of October 2020, with following columns available (table \@ref(data-dictionary)). Source data and steps of data cleaning are elaborated in the [data](#data) section in the appendix. 



```{r, results="asis"}
tribble(
  ~ Variable, ~ Definition, ~ Note,
  "survived", "Survival Status", "0 = Lost, 1 = Saved",
  "age", "Age", "In years, some infants had fractional values",
  "gender", "Gender", "",
  "class", "Cabin class", "1st, 2nd, 3rd or Crew",
  "nationality", "Motherland", "from wiki passenger list",
  "title", "Title", "Extracted from name",
  "spouse", "\\# of spouse on board", "",
  "sibling", "Number of siblings on board", "",
  "parent", "Number of parents on board", "",
  "children", "Number of children on board", "",

) %>% 
  mylatex(file = "", 
          table.env = TRUE, label = "data-dictionary", size = "small",
          caption = "Cleaned data with 2208 rows and 11 columns", rowname = NULL, where = "h")
```


After appropriate formatting and cleaning, the data at hand recorded the survival status `r nrow(t)` Titanic travelers alongside his/her gender, age, companions on board, title, nationality, etc. There were `r (t %>% count(survived))[["n"]][[1]]` victims and `r (t %>% count(survived))[["n"]][[2]]` survivors in total. 

It is essential for every fruitful task of data analysis to first identify key questions of investigation that facilitates interpretation, however vague they are at the beginning. Then we can approach the core problem, filtering out trivialities, with statistical expression by abstraction. For our purposes, we could establish the following questions for which to quest

- To which degree is *Women and children first* policy respected? After the collision, the captain explicitly issued an order for women and children to be saved first.^[Though there is no international maritime law enforcing this kind of chivalry.] Thus we should expect significantly higher proportion of females and children rescued than that in males and adults. If the opposite is true, that Titanic subjects behave more in line with the selfish *homo oeconomicus*, where everybody looked out for himself or herself and possibly even puts other peopleâ€™s lives in danger, then people in their prime with physical superiority would see higher probability of survival. This requires us to study gender and age effect. 


- Did socio-economic advantages mean better chance of survival? If this is the case, passengers with higher financial means, i.e. who live in the first class are more likely to survive. Similarly,  passengers from second class will have a higher change of survival than third class people. Cabin class's impact on survival status needs special notice here. 

- For those who traveled alone with no companions (spouse, sibling, parent, children) on the vessel, is their survival possibility greater or less? On one hand, they are more likely to be in shortage of psychological and physical support. On the other hand, they would may be able to reach a life-saving decision faster without transaction cost and negotiation.  

- Did English subjects receive any special care or given priority to aboard lifeboats? After all, Titanic was operated by British crew, and managed by British captain, masters and officers. Conversely, British nobility and elite 

- Quantify interactions among various characteristics. Specifically, there are important interactions that need extra notice. For example, it has been widely studied in sociology and anthropology that human are sometimes driven by *procreation instinct* so that social norms would entail needs to protect females of reproductive age [@frey2009surviving].^[The average peak reproductive period in females is between the ages of 16 and 35.] Therefore, we could specify and study the interaction between age and gender. Another typical interaction is between offspring and gender. *Parental investment* suggest that women on average invest more in caring for their offspring than males. In times of a disaster,  higher opportunity cost will alert females with offspring more than others, and make them seek more aggressively for changes to secure the children as well as themselves.  


This case study has been greatly inspired by Dr. Frank Harrell's similar example in his *Regression Modeling Strategies* [-@harrell2015regression Chapter 12] book, here I attempt to propose my understanding and interpretation of model development that is as original as possible. To ensure reproducibility, all the analysis is done in R [@base] with code and text made public in this [repo](https://github.com/enixam/titanic-survival). A brief summary of each section is listed below 

- [Exploration](#exploration). Use descriptive statistics to examine data distribution characteristics, data missing patterns and relative effects, followed by redundancy analysis to study dependencies among predictors. Finish with nonparametric loess regression exploring nonlinear trends. 

- [Model development](#dev). The key section in specifying, developing, validating and describing a binary logistic model, split into 

  - [Specification](#spec) Prespecification of predictor complexity with a saturated model. Guide later development of the final model with importance ranking based on bootstrap resampling. 
  
  - [Multiple imputation](#imputation): Use predictive mean matching to impute subject's age, resulting in 30 complete dataset. 
  
  - [Model fitting, validation and calibration](#fit). Obtain pooled parameter estimates based on prespecified complexity and imputation results. Use bootstrap validation and calibration curve (the ".632" method) to study model performance and optimism. 

  - [Interpratation](#interpretation). Summarize the model with estimation and hypothesis testing, combined with graphical methods like partial effect plots and nomogram. 
  
  
- [Discussion](#discussion). Model-based explanation to address former questions. 

- [Conclusion](#conclusion). Conclusion and further study.  



# Exploration {#exploratory}

## Descriptive statistics and data processing {#descriptive}

A graphical summary of of the data is given by the `Hmisc::describle` function. For numerical variables, a inline histogram is produced alongside summary measures such as the number of missing values and the mean. For discrete variables, we focus on the number of categories and their relative frequency.  

```{r, echo = TRUE, results = "asis"}
# print a summary for the data
t %>% 
  describe() %>%
  latex(file = "", size = "small", center = "none")
```


There are several noteworthy patterns.^[Though this may not be relevant to the model, it is still an surprising discovery that it wasn't until the late 19th century that the idea of women traveling alone gained ground. As a result, there were nearly twice as many males passengers as females on Titanic. In fact, only 40% female passengers have no companion on the ship.] 

Of special importance is the `age` variable, which has roughly 30% missingness. On the other hand, it has a nearly symmetric distribution with 80% known observations falling between 14 and 50. For further examination of patterns of missing data, we could fit a decision tree to predict which type of subject tend to have missing ages. Generally, for some third class male passenger or crew, age is mostly to miss. 

```{r na-tree, echo = TRUE, fig.cap = "(ref:na-tree)", fig.height = 3.5}
na_tree <- rpart(factor(is.na(age)) ~ ., 
                 data = t %>% mutate(survived = as.factor(survived)) , 
                 minbucket = 50)
# figure 1
rpart.plot::rpart.plot(na_tree, type = 3, cex = 0.6)
```

(ref:na-tree) The decision tree for predicting `is.na(age)`, which finds strong patterns of missing related to class/department and  gender (the Syrian node has very limited samples). Each node shows (top to bottom) the predicted class, the predicted probability of age being missing, the percentage of observations in the node.   


We see in figure \@ref(fig:na-tree) that survival status, gender and class are essential in determining age missingness. For a 3rd class male passenger who did not survive, age is missing with a probability of 60%. Interestingly, English male crew members are much more likely to have missing age than subjects of other nationality


Back to other variables in descriptive statistics. Distributions of subject's companion on Titanic are all too narrow, as illustrated in figure \@ref(fig:skew-rel). There is too little variation to model them continuously. This motivates categorization since we will not lose too much information. Lastly, nearly half of the subjects are English. And if we focus on crew, the number rise to 85%. 


```{r skew-rel, fig.cap = "(ref:skew-rel)", fig.height = 3.5, fig.width = 5}
t %>%
  tidyr::pivot_longer(8:11, names_to = "relation", values_to = "n") %>%
  ggplot() + 
  geom_bar(aes(n), color = "black", fill = "midnightblue", alpha = 0.7) +
  facet_wrap(~ relation, nrow = 1) + 
  labs(x = NULL, y = NULL) 
```

(ref:skew-rel) Few subjects have more than one companion in any of the 4 relations.

Given this results, the final step in data munging is to dichotomize `spouse`, `parent`, `children` and `sibling` to denote if there is such relation. Thus we no longer have to deal with continuous predictors with poor distribution. 

```{r}
t$spouse <- if_else(t$spouse == 0, "0", "1")
t$parent <- if_else(t$parent == 0, "0", "1")
t$sibling <- if_else(t$sibling == 0, "0", "1")
t$children <- if_else(t$children == 0, "0", "1")
```

Univariate relationship between each independent variable and survival status is presented in figure \@ref(fig:univariate). For each column, we can build a anova-type plot with no control over confounding variables, though it may still assist us in determining how to spend degrees of freedom. If a predictor's effect on the response is strong, it's more likely that we need to spend more parameters on it. However, if a variable's effect appears to be weak, it could either due to a truly flat relationship, or to nonlinearity and predictors among variables that univariate method cannot detect. 

```{r univariate, fig.height = 7.5, fig.width  = 3.5, fig.cap = "Univariate summary of relationship between survival and each predictor"}
s <- summary(survived ~ ., 
    data = t)
plot(s, main = "" , subtitles = TRUE, cex = 0.65, pch = 22, width = 3)
```

The plot reveals appreciably strong effects of gender and cabin class on survival status. The effect of age seems trivial except for the missing subjects, but again, this figure exposes only linear relationship, and only after categorization. As we will see in the next section, age effect are much nonlinear and concentrated in the young subjects. The downside of this kind of univariate relationship is also exemplified in `title`, where "Miss". For the same reason effects of other variables cannot be determined. 

We will finish with a redundancy analysis to study if any predictor can be readily explained by the rest of predictors, therefore does not much bring new information and may not enter the model. The checking algorithm involves 

```{r, comment = ""}
redun(~ age  + gender + class +  nationality + title + spouse +
        sibling + parent + children
      , data = t)
```

The redundancy analysis has reported , with more than 97% of uts variation explained by the rest of the predictors. 

```{r}
t$title <- NULL
```




## Loess regression for nonlinear pattern 

The loess method is a common nonparametric regression model to study nonlinear relationship. In the case of binary response, the fitted value at $x = x_0$ is the weighted proportion of positive cases near the neighborhood of $x_0$. If the trend of a loess curve exhibits nonmonotoncity, it is reasonable to include that nonlinearity relationship in the model, e.g., modeling the predictor with polynomial transformation or with splines. 

It was widely documented that gender interacts directly with age effects. Another important interaction, according to many follow up studies, happened with cabin class. Figure \@ref(fig:loess-curve) displays loess estimates of survival probability given age under stratification. Not only in a powerful nonlinear fashion does age affect survival status (top left panel), we also observe it interact with other two factors in a nonlinear way. 

```{r loess-curve, fig.height = 7.5, fig.cap = "(ref:loess-curve)"}
p1 <- ggplot(t, aes(age, survived)) +
  histSpikeg(survived ~ age, lowess = TRUE, data = t) + 
  labs(y = NULL, x = NULL)
p2 <- ggplot(t, aes(age, survived, color = gender)) + 
  histSpikeg(survived ~ age + gender, lowess = TRUE, data = t) + 
  labs(y = NULL, x = NULL)
p3 <- ggplot(t, aes(age, survived, color = class)) + 
  histSpikeg(survived ~ age +  class + gender, lowess = TRUE, data = t) + 
  labs(y = NULL) + 
  facet_wrap(~ gender) + 
  theme(legend.position = "bottom")
(p1 + p2) / p3 
```

(ref:loess-curve) `loess` estimates of $P(\text{survived})$, with tick marks representing frequency counts within equal-width bins. Top left panel indicates nonlinear age effect without controlling other factors. Other plots give estimates under stratification by sex and class. The top right plot reflects women have a higher survival probability in general, and older females (red) and younger males (blue) are most likely to survive in their respective gender group. Two bottom plots depict survival pattern of subjects from different cabin class condition on sex.







# Model development {#dev}

A typical modeling workflow begins with an choice of a statistical model or a machine learning model. A statistical model often stems from a hypothesized probabilistic data generating mechanism and assumes additivity, whereas machine learning models is algorithmatic in nature, optimized with parameter tuning. We choose to develop a statistical model, a "simple" binary logistic regression, for the following reasons. 

We prefer probabilistic predictions to classification with output label 0 and 1, since we are placing emphasis upon the *tendency* of survival. And the value of the model consist not in a dichotomous prediction, but in what characteristics would increase or decrease the possibility of survival. The notion has ruled out most of the machine learning models for classification, say, random forest, support vector machines and neural network, which are not intrinsically probability oriented. Such classifiers can often only yield a forced choice. 

Interpretability and inference matters. Many top data science competitions has reported moderately high signal to noise ratio (e.g., 90% prediction accuracy) that might tip the balance towards machine learning models, while interpretability is harmed. Specifically, statistical models favours additivity and explicit specification. It follows that there are natural distinctions between main effects and interactions, linearity and nonlinearity. And the inference procedure is well defined provided that the model is correctly specified. While in a multi-layer neural network, everything can interact with one another and it could be daunting to isolate effects and conduct former inference. 

Machine learning models are data hungry and sometimes create the need for big data [@van2014modern]. To guard against overfitting, the analyst has to have a sample size that is 10 times larger at least if he chooses a tree model instead of regression. While this case study uses a Titanic dataset that is about 1/3 larger than those only concerned with passengers, it is far less sufficient for a typical data-hungry machine learning model to validate well. The rationale is that a statistical model is a safer approach as Dr. Harrell commented

> If n is too small to do something simple, it is too small to do something complex


## Specification {#spec}

We start by fitting a relatively large model, to decide how model complexity should be properly represented. This includes deciding the number of knots for continuous predictors and the number of categories of categorical predictors, could we remove some term, where should we place interaction, etc. The large model also gives an overall sense of the predictive ability of each subject characteristics on survival status. This strategy as a starting point is also called prespecification of predictor complexity. It avoids creating phantom degrees of freedom when one has subjective judgment according to scatter diagrams or descriptive statistics on how to represent variables in a model. Commonly done, for example, is excluding a quadratic term simply because it is "non-significant", with p-value on the edge of $0.05$. This approach is known to distort coefficient estimates, confidence intervals, p-value  and calibration (too optimistic) of the final model [@grambsch1991effects].^[confidence interval too narrow, p-value and standard errors too small and calibration too optimistic] Because it fails to accounts for sampling variability and suffers selection bias. Therefore, it is essential to have extra caution, as demonstrated below using resampling, to do model simplification. 

Prespecification of predictor complexity is done first by developing a saturated logistic model and then making necessary adjustments and improvements. In this model, we granted age effect maximal flexibility represented as natural splines with 5 knots, and all categorical predictors retain their original categories without pooling. Two way interactions have been specified between age and gender, age and class, and age and parent. Since this is an initial model, observations with missing age are not used. The model equation is 

```r
survived ~ (rcs(age, 5) + gender + class)^2 + (rcs(age, 5) * parent) + 
            joined + spouse + sibling + children + nationality 
```

```{r}
dd <- datadist(t)
options(datadist = "dd")
f1 <- lrm(survived ~ (rcs(age, 5) + gender + class)^2 +
            (rcs(age, 5) * parent) +  
            spouse + sibling + children + 
            joined + nationality,
          data = t, x = TRUE, y = TRUE)
```

Table \@ref(fone-anova) sees dominant main effects of gender, age and cabin class, be it linear or nonlinear ($p < 0.0001$). More notably are the strong nonlinear interaction terms between the 3 predictors. Of all 4 companion variables only parent manifests strong influence. The impact of port of embarkation is somewhat ambiguous ($p = 0.14$.). As a graphical illustration, figure \@ref(fig:fone-anova-plot) plots "adjusted" partial $\chi^2$ statistic of each predictor in the saturated model, with correction for degrees of freedom allocated to them.^[The correction is done by subtracting the d.f. from the partial $\chi^2$ statistic, its expected value under the null hypothesis.] This adjustment levels the playing field for comparison of predictive ability. The larger the corresponding adjusted $\chi^2$, the more likely a variable would have a non-flat impact on survival status.  


```{r, results="asis"}
mylatex(anova(f1), file="", size = "small", table.env = TRUE, caption = "Hypothesis testing for the saturated model", label = "fone-anova", where = "h")
```



```{r fone-anova-plot, fig.cap = "(ref:fone-anova-plot)"}
plot(anova(f1))
```

(ref:fone-anova-plot) Ranking of predictive power in the saturated model based on adjusted $\chi^2$ 


As mentioned before, the goal of the saturated model is guiding model complexity. More specifically, should we allocate more degrees of freedom to a certain term because some complex effects has been underrepresented? Or is there a term that is highly irrelevant and could be deleted? The 5-knots natural spline on age and the resulting nonlinear interaction are promising, and further increasing knots or creating high-order interactions causes numerical problems. Therefore it is positive advantage to us to keep them as is. There are also not sufficient reasons to collapse levels for nationality and port.  Binary variables like spouse and sibling have extremely large p-values ($p > 0.5$), indicating relatively small predictive power. Still,  great care should be taken when one attempts to conduct aggressive model simplification based on hypothesis testing and p-values. A reliable way is using bootstrap resampling. Figure \@ref(fig:predictor-ranking) studies the importance of all terms including main effects and interaction over 500 bootstrap resamples. In each resample, we fit the saturated model, rank all 13 terms by the adjusted statistic $\chi^2 - \text{d.f.}$ in ascending order so that 13 is most important and 1 is least important. The height of a bin indicates the number of times a term is ranked at that position. 


```{r, include = FALSE, cache = TRUE}
set.seed(2021)
v1 <- validate(f1, B = 500, bw = TRUE)
```



```{r, cache = TRUE, include = FALSE}
n <- nrow(t)
B <- 500
ranks <- matrix(NA, nrow = B, ncol = 13)
rank_vars <- function(fit) {
  rank(plot(anova(fit), sort = "none", pl = FALSE))
}

Rank <- rank_vars(f1)
for (i in 1:B) {
  j <- sample(n, replace = TRUE)
  fit_boot <- try(update(f1, data = t, subset = j), silent = TRUE)
  if ("try-error" %in% class(fit_boot)) {
    next
  } else if (!fit_boot$fail) {
    ranks[i, ] <- rank_vars(fit_boot)
  }
}
```

```{r predictor-ranking, fig.cap = "(ref:ranking)"}
colnames(ranks) <- names(Rank)
library(ggridges)
ranks %>% 
  as_tibble() %>% 
  na.omit() %>%
  tidyr::pivot_longer(everything(), names_to = "predictor", values_to = "rank") %>% 
  mutate(group = factor(predictor, levels = names(Rank))) %>% 
  ggplot(aes(rank, group, group = group)) + 
  geom_density_ridges2(aes(fill = group), stat = "binline", binwidth = 1) +
  scale_fill_cyclical(values = c("#0000B0", "#7070D0")) +
  geom_text(aes(y = group + 0.95*after_stat(count/max(count)), 
                label = ifelse(after_stat(count) >= 40, after_stat(count), "")), 
            stat = "bin", color = "white", size = 3) + 
  labs(y = NULL) + 
  theme_ridges() + 
  theme(axis.title.x = element_text(hjust =  0.5)) + 
  scale_x_continuous(breaks = 1:13) + 
  scale_y_discrete(expand = c(0, 0))  
```

(ref:ranking) Distribution of importance ranking over 500 bootstrap resamples, 412 of which are actually fitted without numerical problems. Text indicates the number of times a term has a specific ranking, when the term ranked more than 40 times at that position. For example, gender ranks 13 (the most important) in all valid resamples.  


The importance ranking echoes previous findings that gender, age and cabin class are predominant factors. It also reveals great variability in terms of assessing predictive power. For example, we are only confident that `joined` is not one of the 5 most influential predictors. Nonetheless, rankings of the aforementioned "weak" variables, sibling and spouse, are highly concentrated at 1 to 3.  In fact, if we perform backward selection in nearly 500 bootstrap resamples with AIC as stopping rule, none of the 3 binary variables entered the selected model more than 20 times. This results in the final decision to remove them in the final model. 

```{r, echo = TRUE}
t$sibling <- NULL
t$spouse <- NULL
```



## Multiple imputation {#imputation}

The last step before fitting the final model is imputing missing values for age. The goal of multiple imputation, in contrast to simple alternatives such as filling in conditional mean, is to provide an accurate estimate of the variance-covariance matrix that not only accounts for sampling variability, but also for the extra variance caused by missing values and finite number of imputations [@van2018flexible]. Thus tests on individual parameters gain power and bias are reduced. The general idea is to generate multiple complete dataset, fit the model in parallel, and then obtain a pooled final estimate by averaging over all fitted models. 


We use predictive mean matching with $m = 30$, since approximately 30% age are missing. The method selects a group of Titanic subjects from all complete cases that have predicted values closest to the predicted value for the subject with missing age. ^[The predicted value is generated by fitting a linear main effect model conditional on all other variables.] One donor is randomly drawn from the candidates, and the observed age of the donor is taken to replace the missing value. We use the default "type 1 matching" and 5 donors (@van2018flexible, Section 3.4.2). Advantages of predictive mean matching in the Titanic age setting are manifold. Since imputations are based on values observed elsewhere, they are realistic (e.g., no negative age). For another, it is compatible with non-normaility which allows us to have fewer assumptions. 


```{r, cache = TRUE, echo = TRUE}
# multiple imputation with predictive mean matching to generate 30 complete dataset
imp <- mice(t, method = "pmm", m = 30, printFlag = FALSE)
```

```{r, fig.width = 5, fig.height = 3, fig.cap = "Density plot of observed and imputed data. In general, the imputed dataset mimic the age distribution seen in the observed data."}
densityplot(imp)
```







## Model fitting, validation and calibration {#fit}

We fit the final logistic model for 30 complete dataset. Parameter estimates are obtained by averaging over all dataset. We also get an imputation-corrected varianceâ€“covariance matrix based on withinâ€“ and betweenâ€“imputation variances. 
```{r, include = FALSE, cache = TRUE}
f2 <- fit.mult.impute(survived ~ (rcs(age, 5) + gender + class)^2 +
            rcs(age, 5) * parent + children + nationality + joined,
            fitter = lrm, 
            imp, 
            data = t)
```

Table \@ref(ftwo-anova) again lists meaningful hypothesis testing for the final model. The $\chi^2$ statistic of age decreased by a minor amount, resulting from using patterns of association with survival status to impute missing age. Remaining predictors generally have larger $\chi^2$ statistic and smaller p-value compared to the saturated model in table \@ref(fone-anova), due to larger sample size in model development. Table \@ref(model-index) prints model assessment metrics and details individual parameters. The model exhibits moderate discrimination power, e.g. the ability to separate perished and survived subjects (concordance probability $=$ area under the ROC curve $\approx 0.81$).  Brier score, as a proper quadratic scoring rule that incorporate both aspects, is a promising $0.144$. 


```{r, results = "asis"}
mylatex(anova(f2), file = "", size = "small", table.env = TRUE, label = "ftwo-anova",
        caption = "Hypothesis testing for the final model", where = "h")
```



\begin{table}[h]
\caption{Model index and estimation\label{model-index}} 
\begin{center}\small
\begin{tabular}{|c|c|c|c|}
\hline
&Model Likelihood&Discrimination&Rank Discrim.\\
&Ratio Test&Indexes&Indexes\\\hline
Obs~\hfill 2208&LR $\chi^{2}$~\hfill 783.83&$R^{2}$~\hfill 0.418&$C$~\hfill 0.813\\
~~0~\hfill 1496&d.f.~\hfill 41&$g$~\hfill 1.799&$D_{xy}$~\hfill 0.626\\
~~1~\hfill 712&Pr$(>\chi^{2})$~\hfill \textless 0.0001&$g_{r}$~\hfill 6.053&$\gamma$~\hfill 0.628\\
$\max|\frac{\partial\log L}{\partial \beta}|$~\hfill 0.007&&$g_{p}$~\hfill 0.274&$\tau_{a}$~\hfill 0.274\\
&&Brier~\hfill 0.144&\\
\hline
\end{tabular}
\end{center}
\end{table}

\small
\setlongtables\begin{longtable}{lrrrr}
\hline
\multicolumn{1}{l}{}&\multicolumn{1}{c}{$\hat{\beta}$}&\multicolumn{1}{c}{S.E.}&\multicolumn{1}{c}{Wald $Z$}&\multicolumn{1}{c}{Pr$(>|Z|)$}\tabularnewline
 \hline
 \endhead
 \hline
 \endfoot
 Intercept&~ -0.1475~&~ 1.9879~&-0.07&0.9409\tabularnewline
 age&~  0.2225~&~ 0.1244~& 1.79&0.0737\tabularnewline
 age'&~ -0.9850~&~ 0.6877~&-1.43&0.1520\tabularnewline
 age''&~  4.4844~&~ 3.6008~& 1.25&0.2130\tabularnewline
 age'''&~ -5.5980~&~ 4.9656~&-1.13&0.2596\tabularnewline
 gender=Male&~ -1.8842~&~ 1.0197~&-1.85&0.0646\tabularnewline
 class=2nd&~  5.4575~&~ 2.8123~& 1.94&0.0523\tabularnewline
 class=3rd&~ -1.0535~&~ 1.8583~&-0.57&0.5708\tabularnewline
 class=crew&~ -2.4149~&~ 3.2651~&-0.74&0.4595\tabularnewline
 parent=1&~  3.4640~&~ 1.2035~& 2.88&0.0040\tabularnewline
 nationality=English&~  0.0730~&~ 0.2757~& 0.26&0.7912\tabularnewline
 nationality=Finnish&~  0.1843~&~ 0.4289~& 0.43&0.6674\tabularnewline
 nationality=Irish&~  0.0116~&~ 0.3901~& 0.03&0.9763\tabularnewline
 nationality=Other&~ -0.2328~&~ 0.2669~&-0.87&0.3832\tabularnewline
 nationality=Swedish&~ -0.2673~&~ 0.3820~&-0.70&0.4840\tabularnewline
 nationality=Syrian&~ -0.0582~&~ 0.4429~&-0.13&0.8955\tabularnewline
 joined=Cherbourg&~  0.6565~&~ 0.3321~& 1.98&0.0480\tabularnewline
 joined=Queenstown&~  0.0538~&~ 0.4133~& 0.13&0.8965\tabularnewline
 joined=Southampton&~ -0.0632~&~ 0.2003~&-0.32&0.7523\tabularnewline
 age $\times$ gender=Male&~ -0.1498~&~ 0.0573~&-2.61&0.0090\tabularnewline
 age' $\times$ gender=Male&~  0.8213~&~ 0.3849~& 2.13&0.0329\tabularnewline
 age'' $\times$ gender=Male&~ -3.9560~&~ 2.3149~&-1.71&0.0875\tabularnewline
 age''' $\times$ gender=Male&~  4.8271~&~ 3.5665~& 1.35&0.1759\tabularnewline
 age $\times$ class=2nd&~ -0.3846~&~ 0.1754~&-2.19&0.0283\tabularnewline
 age' $\times$ class=2nd&~  1.4771~&~ 0.8999~& 1.64&0.1007\tabularnewline
 age'' $\times$ class=2nd&~ -6.7250~&~ 4.5517~&-1.48&0.1395\tabularnewline
 age''' $\times$ class=2nd&~  8.5082~&~ 6.1731~& 1.38&0.1681\tabularnewline
 age $\times$ class=3rd&~ -0.1403~&~ 0.1159~&-1.21&0.2262\tabularnewline
 age' $\times$ class=3rd&~  0.7699~&~ 0.6331~& 1.22&0.2240\tabularnewline
 age'' $\times$ class=3rd&~ -4.9212~&~ 3.2961~&-1.49&0.1354\tabularnewline
 age''' $\times$ class=3rd&~  7.7752~&~ 4.5292~& 1.72&0.0860\tabularnewline
 age $\times$ class=crew&~  0.0589~&~ 0.1890~& 0.31&0.7554\tabularnewline
 age' $\times$ class=crew&~ -0.0468~&~ 0.8023~&-0.06&0.9535\tabularnewline
 age'' $\times$ class=crew&~ -0.5748~&~ 3.6057~&-0.16&0.8733\tabularnewline
 age''' $\times$ class=crew&~  1.5477~&~ 4.4606~& 0.35&0.7286\tabularnewline
 gender=Male $\times$ class=2nd&~ -0.4060~&~ 0.7087~&-0.57&0.5667\tabularnewline
 gender=Male $\times$ class=3rd&~  2.1475~&~ 0.6288~& 3.41&0.0006\tabularnewline
 gender=Male $\times$ class=crew&~  0.5495~&~ 0.8726~& 0.63&0.5289\tabularnewline
 age $\times$ parent=1&~ -0.1190~&~ 0.1118~&-1.06&0.2871\tabularnewline
 age' $\times$ parent=1&~ -0.6885~&~ 1.1693~&-0.59&0.5560\tabularnewline
 age'' $\times$ parent=1&~ 10.4417~&~11.6224~& 0.90&0.3690\tabularnewline
 age''' $\times$ parent=1&~-29.7852~&~35.4739~&-0.84&0.4011\tabularnewline
 \hline
 \end{longtable}
 \addtocounter{table}{-1}


\normalsize




Although there will not be a second Titanic, making prediction a lesser problem, validation can still be used for good purposes. It quantifies the degree of overfitting by presented unbiased, optimism-corrected measures. More accurately, we will be using bootstrap internal validation to study the "future" performance of the model. In an award-winning solution to this legendary dataset submitted by IBM Watson, a holdout test set was used to validate their model. The data-splitting approach is known to require a significantly larger sample size ($> 20000$) than resampling methods on average to work acceptably well [@splitval]. Moreover, when the model developed on training sample is validated, the researcher would recombine training and testing set to fit a full model. This model, however, is never validated. 


```{r, include = FALSE, cache = TRUE}
f2 <- update(f2, x = TRUE, y = TRUE)
v2 <- validate(f2, B = 500, method = ".632")
```


As an improved alternative, we choose Efron's 0.632 method for bootstrap internal validation. In each of the 494 bootstrap resamples, a model is developed and evaluated on observations omitted from bootstrap samples. Per-bootstrap optimism is then the apparent index of accuracy subtracting that in the test sample formed by omitted observations. An weighted average $\hat{\varepsilon}_0$ over all 494 bootstrap resamples is computed to estimate the true optimism, while the bias-corrected
estimate of predictive accuracy is calculated as $0.632(\text{apparent accuracy} - \hat{\varepsilon}_0)$. Table \@ref(model-val) displays the results. It validates two general aspects of model accuracy, discrimination and calibration. Calibration is the ability to make unbiased estimates of survival status, while discrimination is the a measure in how separated predictions are for survivors and victims. 

```{r, results = "asis"}
mylatex(v2, file = "", size = "small", table.env = TRUE,
        label = "model-val", caption = "Optimism-corrected metrics", where = "h")
```


The output does not deviate much from the apparent index. The validated area under the ROC curve as well as the concordance probability is now `r round((v2["Dxy", "index.orig"]/2)+0.5, 2)`, and pseudo $R^2$ 0.35.  This indicates certain shortage of discrimination ability in comparison to some published models on the older dataset, resulting in an moderate accuracy of $0.81$ with cutoff at $0.5$. $\text{Slope} = 0.8$ signals small amount of overfitting, with coefficients shrinking by 20% on new data.^[$D_{xy} = 2(\text{concordance proabability - 0.5})$]. Brier score is now near 0.15. 

Aside from rank-based discrimination metrics, figure \@ref(fig:cal-curve) aims to gauge the concordance between predicted values and observed data, or in other words, calibration.  The actual probability is estimated with loess regression, and the bias correction is achieved in a similar way as in table \@ref(model-index). The 45 degree line indicates the ideal scenario in which prediction perfectly matches observation. The model is well-calibrated by and large, with slight departure from the straight line in lower and certain middle region. The mean squared error and 0.9 quantile of absolute error
is 0.00018 and 0.023 respectively. 

To sum up, the model presents reasonable discrimination power and satisfactory quality of fitting. Excellent performance in calibration lifts overall metrics such as Brier score

```{r, cache = TRUE, include = FALSE}
cal <- calibrate(f2, B = 500)
```



```{r, cal-curve, fig.cap = "Bias-corrected calibration curve of the model output probabilites on bootstrap resamples", out.width = "90%"}
knitr::include_graphics("cal-curve.png")
```




## Interpretation 












```{r}
ggplot(Predict(f2, age, gender, class, 
               parent = 0, children = 0, nationality = "English", joined = "Southampton",
               fun = plogis, ))
```

```{r}
ggplot(Predict(f2, joined, fun = plogis))
```










https://www.encyclopedia-titanica.org/community/threads/passengers-who-spoke-other-languages.20103/

Since the crew's instructions (in English) tended to be along the lines of "Wait down here for further orders" a lack of understanding might well have saved many lives. Also many of the immigrants in 3rd class were traveling in family or neighborhood groups which included at least one English-speaker (often an established immigrant returning to the US from a visit back home) who could act as their spokesperson.




# Discussion 


The most decisive explanation for such effect is that first-class passengers had better access to information about the
imminent danger and were aware that the lifeboats were located close to the first class cabins. Thus, their marginal effort costs to survive were lower. In contrast, most third-class passengers had no idea where the lifeboats were located (safety drills for all passengers were introduced after the Titanic disaster), and they did not know how to reach the upper decks where the lifeboats were stowed.  

Wyn Craig Wade: there was a class culture on Titanic akin to the notion of a "culture of poverty

> Undoubtedly, the worst barriers were the ones within the steerage passengers themselves. Years of conditioning as third-class citizens led a great many of them to give up hope as soon as the crisis became evident ... Barriers to steerage? Yes, but of a kind less indictable to the White Star Line than to the whole of civilization.


A more detailed explanation of some of these measures is presented in the [appendix](#measures). 

*Women and children first only for higher class passengers*. If you are a third class female



# Conclusion 





\pagebreak


# (APPENDIX) Appendix {-} 


# Data

A variety of other versions and forms of Titanic data sources have been collected due to public's constant interests in the tragedy as well as modern efforts trying to unveil the mystery. A comprehensive overview of several data variants is given by @symanzikunsinkable. Data in this case study is accessed on [Encyclopedia Titanica](https://www.encyclopedia-titanica.org/), a leading archive on titanic facts.  In contrast to the the famous titanic dataset (known as `titanic3`) distributed by [kaggle](kaggle.com) for introductory level machine learning practices, the case study uses a more up-to-date and complete dataset in the following ways

- **Larger sample size**. Our data includes crew and staff members alongside passengers, while titanic3 only incorporate passenger information. We do not use a separate test set approach for validation either. As a result, the sample size is about 2.5 times larger. 

- **More columns**. Additional variables such as role on the ship, nationality and occupation are added. A major difference is made by separating the travel companion data into four distinct columns: number of parents, children, sibling and spouses that each passenger traveled with. These were combined into two columns before. 

- **More accurate**. `titanic3` was an effort to study Titanic in the 20th century, lastly updated and improved by Thomas Cason in 1999. During the recent two decades the data has been constantly revised, many errors corrected, many missing ages filled in, and new variables created. Now it reflects our our most up-to-date understanding of the event, in the digital form, as of 21 October 2020. 


The data cleaning process involves using appropriate data types, creating new features, adjusting levels for categorical variable and excluding irrelevant columns. Code can be found at [clean.R](https://github.com/enixam/titanic-survival/clean.R).

`title` is extracted through each person's name with regular expressions and then collapsed into 4 levels.^[For example, the title for passenger "Abbing, Mr Anthony" is "Mr".] This is a predictor that has been widely reported to have good predictive ability in many submissions. However, as we see in the redundancy analysis at the end of Section \@ref(descriptive), it should not even be accepted in the tentative, saturated model. 

Passengers are classified according to their cabin class. Others on the vessel fall into one of crew and staff members. Crew includes victualling crew^[crew in charge of food, housekeeping, laundry, room service, etc.], engineering crew, deck crew and officers, substitute crew and guarantee group. Staff members include restaurant staff and orchestra. 

Rare nationality (lower than 50 people) is collapsed. 

Age information is presented as non-missing on the surface yet there is an indicator column representing when a person's age is only approximate and cannot be fully determined from current facts. These inaccurate age have been assigned NA. There were also ten subjects whose four companion variables were all explicitly missing. For simplicity, the mode `0` is filled in. Therefore, the problem of missing data is reduced to univariate missing of `age`.   

Variables we do not utilize in this project includes name, date of birth and death, lifeboat number^[There were 9 recorded passengers who got on the lifeboat yet died before reaching Carpathia, another RMS which spearheaded the rescue of Titanic survivors. There were also 13 passengers who survived with no boat information documented, and this is most likely due to data quality issues after looking up on Encyclopedia Titanica. Even with these exceptions, whether a passenger got on a lifeboat yields perfect prediction on his/her survival. If one fits a logistic regression model on survival based on whether `boat` is missing, the apparent accuracy will be nearly 1. In this sense `boat` is more the result of survival, rather than a cause.], fare, and cabin number.^[While some study used this attribute to find cabin locations, its large amount of missingness could be a major source of complexity.]

# Model formula 

The formula for our binary logistic model 





# Criterion used in model validation {#measures}

Somer's $D_{xy}$ index is a calibration measure, which is the rank correlation between predicted and actual response. It has a close relationship with the C index 



# Computing environment

```{r, comment = "", echo = TRUE}
sessionInfo()
```


```{r bib,include=FALSE,cache=FALSE, eval = FALSE}
# automatically create a bib database for R packages
bib <- knitr::write_bib(
  x = c(
    .packages(), "knitr", "rmarkdown", "bookdown", "rticles"
  ), file = NULL, prefix = ""
)
bib <- unlist(bib)
# remove the ugly single quotes required by CRAN policy
bib <- gsub("(\\\n)", " ", bib)
readr::write_lines(bib, "references.bib", append = TRUE)
```

\nocite{*}
