---
title: |
  Modeling Titanic Survival
author:
  - name: Qiushi Yan
    affil: ""
    email: "qiushi.yann@gmail.com, website: https://qiushi.rbind.io"
affiliation:
  - num: a
    address: |
      Beijing, China
abstract: |
   This case study showcases the development of a binary logistic model to predict the possibility of survival in the loss of Titanic. I demonstrate the overall modeling process, including preprocessing, exploratory analysis,  model fitting, adjustment, bootstrap validation and interpretation as well as other relevant techniques such as redundancy analysis and multiple imputation for missing data. The motivation and justification behind critical statistical decisions are explained. This analysis is fully reproducible with all source R code and text. 
bibliography: references.bib
link-citations: true
geometry: "margin=1in"
colorlinks: yes
#appendix: appendix.tex
output:
  bookdown::pdf_book:
    base_format: rticles::tf_article
    includes:
      in_header: header.tex
    dev: "cairo_pdf"
    extra_dependencies:
      sourcecodepro:
       - scale=0.85
      sourceserifpro:
       - rmdefault
      sourcesanspro:
       - sfdefault
---

http://www.crema-research.ch/papers/2009-03.pdf

Who Survived Titanic? A Logistic Regression Analysis: https://sci-hub.do/https://journals.sagepub.com/doi/pdf/10.1177/084387140401600205


https://www.insider.com/titanic-secrets-facts-2018-4#at-the-memorial-of-frederick-fleet-one-of-the-lookouts-a-prankster-left-a-pair-of-binoculars-with-a-note-reading-sorry-for-bringing-these-100-years-too-late-8


http://rpubs.com/edwardcooper/titanic1

https://www.kaggle.com/mrisdal/exploring-survival-on-the-titanic/report

https://www.kaggle.com/startupsci/titanic-data-science-solutions/comments

https://www.newscientist.com/article/dn22119-sinking-the-titanic-women-and-children-first-myth/

```{r, include = FALSE}
# global chunk options 
knitr::opts_chunk$set(
  warning = FALSE,
  message = FALSE,
  comment = "",
  fig.align = "center",
  echo = FALSE
)

# load libraries 
library(dplyr) # data wrangling
library(ggplot2) # visualization
library(rms) # modeling
library(mice) # imputation for missing data
library(patchwork) # plot composition
library(rpart) # decision tree for mis
# latex print option
options(prType='latex')
# load raw data
t <- readr::read_csv("data/titanic.csv") 
# modify Hmisc::latex
mylatex <- function (...) {
    o <- capture.output(latex(...))
    # this will strip /all/ line-only comments
    o <- grep('^%', o, inv=T, value=T)
    cat(o, sep='\n')
}
# theme for ggplot2
theme_clean <- function(base_size = 11,
                      strip_text_size = 12,
                      strip_text_margin = 5,
                      subtitle_size = 13,
                      subtitle_margin = 10,
                      plot_title_size = 16,
                      plot_title_margin = 10,
                      ...) {
  ret <- ggplot2::theme_minimal(base_size = base_size, ...)
  ret$strip.text <- ggplot2::element_text(
    hjust = 0, size = strip_text_size,
    margin = ggplot2::margin(b = strip_text_margin)
  )
  ret$plot.subtitle <- ggplot2::element_text(
    hjust = 0, size = subtitle_size,
    margin = ggplot2::margin(b = subtitle_margin)
  )
  ret$plot.title <- ggplot2::element_text(
    hjust = 0, size = plot_title_size,
    margin = ggplot2::margin(b = plot_title_margin)
  )
  ret$plot.title.position <- "plot"
  ret$panel.grid <- ggplot2::element_blank()
  ret
}
ggplot2::theme_set(theme_clean())
```




# Introduction 

The sinking of RMS Titanic brought to numerous machine learning competitions a quintessential dataset among others. After the "unsinkable" British passenger liner struck an iceberg in her maiden voyage on 15 April 1912 and was eventually wrecked, more than 1500 people perished. Decades of effort has been devoted to the study of the historic event, in which one major interest for statistical inquiries is to model and predict survival given a number of characteristics, since there was clear account that some people  were allowed to get on the lifeboat first.  

There are numerous variants of Titanic data existed on the web, with primary source based on [Encyclopedia Titanica](https://www.encyclopedia-titanica.org/) [-@hind],  a site started in 1996 as an attempt to tell the story of every person that traveled the Titanic as a passenger or
crew member. This project is based on the most recent version as of October 2020, with following columns available (table \@ref(data-dictionary)). Source data and steps of data cleaning are elaborated in the [data](#data) section in the appendix. 



```{r data-dictionary,results="asis"}
tribble(
  ~ Variable, ~ Definition, ~ Note,
  "survived", "Survival Status", "0 = Lost, 1 = Saved",
  "age", "Age", "In years, some infants had fractional values",
  "gender", "Gender", "",
  "class\\_dept", "Class or Department", "Passengers, Crew or Staff",
  "nationality", "Motherland", "from wiki passenger list",
  "title", "Title", "Extracted from name",
  "spouse", "\\# of spouse on board", "",
  "sibling", "Number of siblings on board", "",
  "parent", "Number of parents on board", "",
  "children", "Number of children on board", "",

) %>% 
  mylatex(file = "", 
          table.env = TRUE, label = "data-dictionary", size = "small",
          caption = "Cleaned data with 2208 rows and 11 columns", rowname = NULL, where = "h")
```


After appropriate formatting and cleaning, the data at hand recorded the survival status `r nrow(t)` Titanic travelers alongside his/her gender, age, companions on board, title, nationality, etc. There were `r (t %>% count(survived))[["n"]][[1]]` victims and `r (t %>% count(survived))[["n"]][[2]]` survivors in total. 

It is essential for every fruitful task of data analysis to first identify key questions of investigation that facilitates interpretation, however vague they are at the beginning. Then we can approach the core problem, filtering out trivialities, with statistical expression by abstraction. For our purposes, we could establish the following questions for which to quest

- To which degree is *Women and children first* policy respected? After the collision, the captain explicitly issued an order for women and children to be saved first.^[Though there is no international maritime law enforcing this kind of chivalry.] Thus we should expect significantly higher proportion of females and children rescued than that in males and adults. If the opposite is true, that Titanic subjects behave more in line with the selfish *homo oeconomicus*, where everybody looked out for himself or herself and possibly even puts other peopleâ€™s lives in danger, then people in their prime with physical superiority would see higher probability of survival. This requires us to study gender and age effect. 


- Did socio-economic advantages mean better chance of survival? If this is the case, passengers with higher financial means, i.e. who live in the first class are more likely to survive. Similarly,  passengers from second class will have a higher change of survival than third class people. Cabin class's impact on survival status needs special notice here. 

- For those who traveled alone with no companions (spouse, sibling, parent, children) on the vessel, is their survival possibility greater or less? On one hand, they are more likely to be in shortage of psychological and physical support. On the other hand, they would may be able to reach a life-saving decision faster without transaction cost and negotiation.  

- Did English subjects receive any special care or given priority to aboard lifeboats? After all, Titanic was operated by British crew, and managed by British captain, masters and officers. Conversely, British nobility and elite 

- Quantify interactions among various characteristics. Specifically, there are important interactions that need extra notice. For example, it has been widely studied in sociology and anthropology that human are sometimes driven by *procreation instinct* so that social norms would entail needs to protect females of reproductive age [@frey2009surviving].^[The average peak reproductive period in females is between the ages of 16 and 35.] Therefore, we could specify and study the interaction between age and gender. Another typical interaction is between offspring and gender. *Parental investment* suggest that women on average invest more in caring for their offspring than males. In times of a disaster,  higher opportunity cost will alert females with offspring more than others, and make them seek more aggressively for changes to secure the children as well as themselves.  


This case study has been greatly inspired by Dr. Frank Harrell's similar example in his *Regression Modeling Strategies* [-@harrell2015regression Chapter 12] book, here I attempt to propose my understanding and interpretation of model development that is as original as possible. To ensure reproducibility, all the analysis is done in R [@base] and RStudio with code and text made public in this [repo](https://github.com/enixam/titanic-survival). A brief summary of each section is listed below 

- [Exploration](#exploration). Use descriptive statistics to examine data distribution characteristics, data missing patterns and relative effects, followed by redundancy analysis to study dependencies among predictors. Finish with nonparametric loess regression exploring nonlinear trends. 

- [Model development](#dev). The key section in specifying, developing, validating and describing a binary logistic model, splitted into 

  - [Specification](#spec) Prespecification of predictor complexity with a saturated main effect model. 
  
  - [Multiple imputation](#imputation): Use predictive mean matching to impute subject's age, resulting in 30 complete datasets. 
  
  - [Model fitting, validation and calibration](#fit). Obtain pooled parameter estimates based on prespecified complexity and imputation results. Use bootstrap validation and calibration curve (the ".632" method) to study model performance and optimism. 

  - [Interpratation](#interpretation). Summarize the model with estimation and hypothesis testing, combined with graphical methods like partial effect plots and nomogram. 
  
- [Discussion](#discussion). Model-based explanation to address some of our former questions. 

- [Conclusion](#conclusion). Conclusion and further study.  



# Exploration {#exploratory}

## Descriptive statistics and data processing

A graphical summary of of the data is given by the `Hmisc::describle` function. For numerical variables, a inline histogram is produced alongside summary measures such as the number of missing values and the mean. For discrete variables, we focus on the number of categories and their relative frequency.  

```{r, echo = TRUE, results = "asis"}
# print a summary for the data
t %>% 
  describe() %>%
  latex(file = "", size = "small", center = "none")
```


There are several noteworthy patterns.^[Though this may not be relevant to the model, it is still an surprising discovery that it wasn't until the late 19th century that the idea of women traveling alone gained ground. As a result, there were nearly twice as many males passengers as females on Titanic. In fact, only 40% female passengers have no companion on the ship.] 

Of special importance is the `age` variable, which has roughly 30% missingness. On the other hand, it has a nice distribution with 80% known observations falling between 14 and 50. For further examination of patterns of missing data, we could fit a decision tree (figure \@ref(fig:na-tree)) to predict which type of subject tend to have missing ages. Generally, for some third class male passenger or crew, age is mostly to miss. 

```{r na-tree, echo = TRUE, fig.cap = "(ref:na-tree)", fig.height = 3.5}
na_tree <- rpart(factor(is.na(age)) ~ ., 
                 data = t %>% mutate(survived = as.factor(survived)) , 
                 minbucket = 50)
# figure 1
rpart.plot::rpart.plot(na_tree, type = 3, cex = 0.6)
```

(ref:na-tree) The decision tree for predicting `is.na(age)`, which finds strong patterns of missing related to class/department and  gender (the Cherbourg node has very limited samples).



Back to other variables in descriptive statistics. Distributions of subject's companion on Titanic are all too narrow, as shown in figure \@ref(fig:skew-rel). This motivates categorization since we will not lose too much information. Lastly, nearly half of the subjects are English. And if we focus on crew, the number rise to 85%. 


```{r skew-rel, fig.cap = "(ref:skew-rel)", fig.height = 3.5, fig.width = 5}
t %>%
  tidyr::pivot_longer(8:11, names_to = "relation", values_to = "n") %>%
  ggplot() + 
  geom_bar(aes(n), color = "black", fill = "midnightblue", alpha = 0.7) + 
  facet_wrap(~ relation, nrow = 2) + 
  labs(x = NULL, y = NULL) + 
  scale_y_log10()
```

(ref:skew-rel) Few subjects have more than one companion in any of the 4 relations. Y axis on log scale.

Given this results, the final step in data munging is to dichotomize `spouse`, `parent`, `children` and `sibling` to denote if there is such relation. Thus we no longer have to deal with continuous predictors with poor distribution. 

```{r}
t$spouse <- if_else(t$spouse == 0, "0", "1")
t$parent <- if_else(t$parent == 0, "0", "1")
t$sibling <- if_else(t$sibling == 0, "0", "1")
t$children <- if_else(t$children == 0, "0", "1")
```

Univariate relationship between each independent variable and survival status is presented in figure \@ref(fig:univariate). This sort of graphical illustration is typical in many flawed infographic visual designs that fail to adjust for real-world complexity. For each column, we can build a anova-type plot with no control over confounding variables, though it may still assist us in determining how to spend degrees of freedom. If a predictor's effect on the response is strong, it's more likely that we need to spend more parameters on it. However, if a variable's effect appears to be weak, it could either due to a truly flat relationship, or to nonlinearity and predictors among variables that univariate method cannot detect. 

```{r univariate, fig.height = 7, fig.width  = 3.5, fig.cap = "Summary of relationship between survival and each predictor"}
s <- summary(survived ~ ., 
    data = t)
plot(s, main = "" , subtitles = TRUE, cex = 0.6, pch = 22, width = 3)
```

The plot shows appreciably strong effects of gender and class/department on survival status. The effect of age seems trivial except for the missing subjects, but again, this figure exposes only linear relationship, and only after categorization. As we will see in the next section, age effect are much nonlinear and concentrated in the young. The downside of this kind of univariate relationship is also exemplified in `title`, one cannot judge whether the. For the same reason effects of other variables cannot be determined. 

We will finish with a redundancy analysis to study if any predictor can be readily explained by the rest of predictors, therefore does not much bring new information and may not enter the model.  The checking algorithm involves 

```{r, comment = ""}
redun(~ age  + class_dept +  nationality + title 
      , data = t)
```





## Loess regression for nonlinear pattern 

The loess method is a common nonparametric regression model to study nonlinear relationship. In the case of binary response, the fitted value at $x = x_0$ is the weighted proportion of positive cases near the neighborhood of $x_0$. If the trend of a loess curve shows nonmonotoncity, it is reasonable to include that nonlinearity relationship in the model, e.g., modeling the predictor with polynomial transformation or with splines. 

Another important interaction, according to many follow up studies, is related to cabin class (for passenger) and department (for crew and staff). 

\@ref(fig:loess-curve)

```{r loess-curve, fig.height = 7.5, fig.cap = "(ref:loess-curve)"}
p1 <- ggplot(t, aes(age, survived)) +
  histSpikeg(survived ~ age, lowess = TRUE, data = t) + 
  labs(y = NULL, x = NULL)
p2 <- ggplot(t, aes(age, survived, color = gender)) + 
  histSpikeg(survived ~ age + gender, lowess = TRUE, data = t) + 
  labs(y = NULL, x = NULL)
p3 <- ggplot(t, aes(age, survived, color = class_dept)) + 
  histSpikeg(survived ~ age +  class_dept + gender, lowess = TRUE, data = t) + 
  labs(y = NULL) + 
  facet_wrap(~ gender)
(p1 + p2) / p3 
```

(ref:loess-curve) `loess` estimates of $P(\text{survived})$, with tick marks representing frequency counts within equal-width bins. Top left panel shows the nonlinear relationship between age and survival status without controlling confounding variables. Other plots give estimates under stratification by sex and class/department.  







# Model devlopment {#dev}

Before any specific modeling workflow, often the analyst has the choice of a statistical model or a machine learning model. A statistical model often stems from a hypothesized probabilistic data generating mechanism and assumes additivity, whereas machine learning models is algorithmatic, optimized through parameter tuning to achieve a higher performance score. We choose the "simple" binary logistic model for the following reasons. 

We prefer probabilistic predictions to classification with output label 0 and 1, since we are placing emphasis upon the *tendency* of survival. And the value of our model consist not in a dichotomous prediction, but in what characteristics would increase or decrease the possibility of survival. The notion has ruled out most of the machine learning models for classification, say, random forest, support vector machines and neural network, which are not intrinsically probability oriented. Such classifiers can often only yield a forced choice. 

Interpretability and inference matters. Although some top data science competitioners has reported moderately high signal to noise ratio (e.x., 90% prediction accuracy) that might tip the balance towards  machine learning models, interpretability is harmed. Specifically, statistical models favour additivity have explicit specification. As a result, there are natural distinctions between main effects and interactions, linearity and nonlinearity. And the inference procedure is well defined provided that the model is correctly specified. While in a multilayer neural network, everything can interact with one another and it could be daunting to isolate effects and conduct former inference. 

Machine learning models are data hungry and sometimes create the need for big data [@van2014modern]. In order to avoid overfitting, the analyst has to have a sample size that is 10 times larger if he chooses a decision tree over regression models. The rationale is that statistical modeling is a safter approach as Dr. Harrell commented

> If n is too small to do something simple, it is too small to do something complex






## Specification {#spec}



the choice of model. , it is hard to interpret main effects and interactions as everything seems to be interacted with one another. 



First and foremost, 

The limiting sample size for binary outcome is the number of minority class, in our case `r sum(t$survived == 1)`. Using the 15:1 rule, that will give us some confidence spending roughly `r round(sum(t$survived == 1) / 15)` parameters or degrees of freedom. 


This plot is used to identify possibly flat relationship between predictor and response. While misuse of this plot would be checking nonlinearity. Even with spline transformation and large corrected $\chi^2$ there is no guarantee for nonlinearity. 


In this sense, the saturated model could provide rough guidance 

represented age as a smooth 5-knot spline function, which costs 4 degrees of freedom. Categorical variables are expanded as dummy variables. restricted to two-way interactions 

```{r, results = "asis"}
tribble(
  ~ "age", ~ "gender", ~ "class\\_dept",
  4, 1, 1,
  4, 4, 4
) %>% mylatex(size = "small", file = "", table.env = TRUE, caption = "(ref:df-budget)", rowname = NULL, where = "h")
```

(ref:df-budget) d.f. budget in the saturated model. Row 1: main effects. Row 2: interactions. 




```{r}
dd <- datadist(t)
options(datadist = "dd")
f1 <- lrm(survived ~ rcs(age, 5) * gender + class_dept +   
            nationality + spouse + sibling + parent + children,
          data = t, x = TRUE, y = TRUE)
```


hypothesis testing 

```{r, results="asis"}
mylatex(anova(f1), file="", size = "small")
```

anova plot

```{r}
plot(anova(f1))
```


to avoid creating "phantom degrees of freedom" that will distort coefficient estimates, confidence intervals, p-value and calibration. 




## Multiple imputation {#imputation}

The pooled estimates are obtained by averaging over $m$ fitted model based on one piece of multiple imputation. The variance-covariance matrix $T$ is calculated using Rudin's rule 

$$
T = \frac{1}{m}\sum_{i=1}^{m}U_i + (1 + \frac{1}{m})B
$$

where $U_i$ is the estimated complete-data variance-covariance matrix in each imputation, and $B$ the estimated variance-covariance matrix between the $m$ complete-data estimates. Here we see the one major advantage of multiple imputation over single imputation is that not only does its variance estimates accounts for sampling variability, but also for the extra variance caused by missing values and finite number of imputations. 


There are some simple workarounds 

- complete-case analysis: That is, we delete all incomplete observations. Needless to say this will translate into a major harm on sample size since over 60% of `boat` are missing, not to mention other columns. Even if we remove `boat` and then delete rows with missing `age` we still lose over 1/5 of data. Moreover, figures in \@ref(exploratory) have shed light on the relatively strong influence of `age` on survival. Also, the deletion of incomplete observations assumes date are missing completely at random (MCAR). When it's not the case, this could severely bias estimates of coefficients [@van2018flexible]

- single imputation: 


- multiple imputation 


```{r, cache = TRUE}
# predictiv mean matching to generate 30 complete datasets
imp <- mice(t, method = "pmm", m = 30, printFlag = FALSE)
```

```{r}
densityplot(imp)
```





https://www.encyclopedia-titanica.org/community/threads/passengers-who-spoke-other-languages.20103/

Since the crew's instructions (in English) tended to be along the lines of "Wait down here for further orders" a lack of understanding might well have saved many lives. Also many of the immigrants in 3rd Class were traveling in family or neighbourhood groups which included at least one English-speaker (often an established immigrant returning to the US from a visit back home) who could act as their spokesperson.



```{r, include = FALSE}
f2 <- fit.mult.impute(survived ~ rcs(age, 4) * gender + class_dept +   nationality + spouse + sibling + parent + children, lrm, imp, data = t)
```






## Model fitting, validation and calibration {#fit}

There will not be another Titanic, and any model on Titanic will not be used for prediction. Therefore, the goal of model validation is primarily to provide quantify the degree of overfitting with various bias-corrected measures. 

The van Houwelingenâ€“Le Cessie heuristic shrinkage estimate

$$
\hat{\gamma} = \frac{\text{model } \chi^2 - p}{\text{model } \chi^2}
$$
where $p$ is the total degrees of freedom and $\chi^2$
the global likelihood ratio statistic for all predictors. 


In the award-winning solution to this legendary dataset presented by IBM Watson, they used a holdout sample to validate their model.  https://www.fharrell.com/post/split-val/


As a integral component of model validation, calibration aims to gauge the concordance between predicted values and observed data. 

## Interpretation 



influence

`which.influence`


```{r, fig.height = 6, fig.cap = "nomogram"}
plot(nomogram(f1), cex.var = 0.8, cex.axis = 0.6)
```









# Discussion 


The most decisive explanation for such effect is that first-class passengers had better access to information about the
imminent danger and were aware that the lifeboats were located close to the first class cabins. Thus, their marginal effort costs to survive were lower. In contrast, most third-class passengers had no idea where the lifeboats were located (safety drills for all passengers were introduced after the Titanic disaster), and they did not know how to reach the upper decks where the lifeboats were stowed.  

Wyn Craig Wade: there was a class culture on Titanic akin to the notion of a "culture of poverty

> Undoubtedly, the worst barriers were the ones within the steerage passengers themselves. Years of conditioning as third-class citizens led a great many of them to give up hope as soon as the crisis became evident ... Barriers to steerage? Yes, but of a kind less indictable to the White Star Line than to the whole of civilization.


A more detailed explanation of some of these measures is presented in the [appendix](#measures). 

*Women and children first only for higher class passengers*. If you are a third class female



# Conclusion 





\pagebreak


# (APPENDIX) Appendix {-} 


# Data

A variety of other versions and forms of Titanic data sources have been collected due to public's constant interests in the tragedy as well as modern efforts trying to unveil the mystery. A comprehensive overview of several data variants is given by @symanzikunsinkable. Data in this case study is accessed on [Encyclopedia Titanica](https://www.encyclopedia-titanica.org/), a leading archive on titanic facts.  In contrast to the the famous titanic dataset (known as `titanic3`) distributed by [kaggle](kaggle.com) for introductory level machine learning practices, the case study uses a more up-to-date and complete dataset in the following ways

- **Larger sample size**. Our data includes crew and staff members alongside passengers, while titanic3 only incorporate passenger information. We do not use a separate test set approach for validation either. As a result, the sample size is about 2.5 times larger. 

- **More columns**. Additional variables such as role on the ship, nationality and occupation are added. A major difference is made by separating the travel companion data into four distinct columns: number of parents, children, sibling and spouses that each passenger traveled with. These were combined into two columns before. 

- **More accurate**. `titanic3` was an effort to study Titanic in the 20th century, lastly updated and improved by Thomas Cason in 1999. The data has been constantly revised, many errors corrected, many missing ages filled in, and new variables created. Now it reflects the state of the data as of 21 October 2020. 


The data cleaning process involves using appropriate data types, creating new features, adjusting levels for categorical variable and excluding irrelevant columns. Code can be found at [clean.R](https://github.com/enixam/titanic-survival/clean.R).

`title` is extracted through each person's name with regular expressions and then collapsed into 4 levels.^[For example, the title for passenger "Abbing, Mr Anthony" is "Mr".]


Passengers are classified according to their cabin class. Others on the vessel fall into one of crew and staff members. Crew includes victualling crew^[crew in charge of food, housekeeping, laundry, room service, etc.], engineering crew, deck crew and officers, substitute crew and guarantee group. Staff members include restaurant staff and orchestra. 

Rare nationality (lower than 50 people) is collapsed. 

Age information is presented as non-missing on the surface yet there is an indicator column representing when a person's age is only approximate and cannot be fully determined from current facts. These inaccurate age have been assigned NA. There were also ten subjects whose four companion variables were all explicitly missing. For simplicity, the mode `0` is filled in. Therefore, the problem of missing data is reduced to univariate missing of `age`.   

Variables we do not utilize in this project includes name, date of birth and death, lifeboat number^[There were 9 recorded passengers who got on the lifeboat yet died before reaching Carpathia, another RMS which spearheaded the rescue of Titanic survivors. There were also 13 passengers who survived with no boat information documented, and this is most likely due to data quality issues after looking up on Encyclopedia Titanica. Even with these exceptions, whether a passenger got on a lifeboat yields perfect prediction on his/her survival. If one fits a logistic regression model on survival based on whether `boat` is missing, the apparent accuracy will be nearly 1. In this sense `boat` is more the result of survival, rather than a cause.], fare, and cabin number.^[While some study used this attribute to find cabin locations, its large amount of missingness could be a major source of complexity.]

# Model formula 

The formula for our binary logistic model 





# Criterion used in model validation {#measures}

Somer's $D_{xy}$ index is a calibration measure, which is the rank correlation between predicted and actual response. It has a close relationship with the C index 

$$
D_{xy} = 2(c - 0.5)
$$

# Computing environment

```{r, comment = "", echo = TRUE}
sessionInfo()
```


```{r bib,include=FALSE,cache=FALSE, eval = FALSE}
# automatically create a bib database for R packages
bib <- knitr::write_bib(
  x = c(
    .packages(), "knitr", "rmarkdown", "bookdown", "rticles"
  ), file = NULL, prefix = ""
)
bib <- unlist(bib)
# remove the ugly single quotes required by CRAN policy
bib <- gsub("(\\\n)", " ", bib)
readr::write_lines(bib, "references.bib", append = TRUE)
```

\nocite{*}
